# ğŸŒ¦ï¸ Pipeline ETL â€” Dados MeteorolÃ³gicos de Votuporanga

Pipeline automatizado de coleta, transformaÃ§Ã£o e armazenamento de dados meteorolÃ³gicos da cidade de **Votuporanga/SP**, orquestrado com Apache Airflow e containerizado com Docker.

---

## ğŸ¯ Objetivo

Construir um pipeline ETL completo que:

- **Extrai** dados meteorolÃ³gicos de Votuporanga via API
- **Transforma** e padroniza os dados coletados
- **Carrega** as informaÃ§Ãµes em um banco de dados PostgreSQL
- **Orquestra** todo o fluxo com Apache Airflow de forma agendada e monitorada

---

## ğŸ›ï¸ Arquitetura

```
pipeline_etl_weather_votu/
â”œâ”€â”€ dags/                   â† DAGs do Apache Airflow
â”œâ”€â”€ notebooks/              â† Notebooks de exploraÃ§Ã£o e anÃ¡lise
â”œâ”€â”€ src/                    â† Scripts Python do pipeline (extract, transform, load)
â”œâ”€â”€ docker-compose.yaml     â† OrquestraÃ§Ã£o dos containers (Airflow + Postgres)
â”œâ”€â”€ main.py                 â† Ponto de entrada do pipeline
â”œâ”€â”€ pyproject.toml          â† DependÃªncias do projeto
â””â”€â”€ README.md
```

### Fluxo do Pipeline

```
API MeteorolÃ³gica
      â†“
   Extract (src/)
      â†“
   Transform (src/)
      â†“
   Load â†’ PostgreSQL
      â†“
   Airflow DAG (agendamento + monitoramento)
```

---

## ğŸ› ï¸ Tech Stack

| Tecnologia | FunÃ§Ã£o |
|---|---|
| **Python** | Linguagem principal do pipeline |
| **Apache Airflow** | OrquestraÃ§Ã£o e agendamento dos DAGs |
| **PostgreSQL** | Armazenamento dos dados transformados |
| **Docker / Docker Compose** | ContainerizaÃ§Ã£o do ambiente completo |

---

## ğŸš€ Como Rodar

### PrÃ©-requisitos

- [Docker](https://docs.docker.com/get-docker/) instalado e rodando
- [Docker Compose](https://docs.docker.com/compose/install/) disponÃ­vel

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/mateusvicentin/pipeline_etl_weather_votu.git
cd pipeline_etl_weather_votu
```

### 2. Suba os containers

```bash
docker-compose up -d
```

Esse comando inicializa:
- **Airflow Webserver** â†’ `http://localhost:8080`
- **Airflow Scheduler** â†’ agendamento dos DAGs
- **PostgreSQL** â†’ banco de dados para os dados meteorolÃ³gicos

### 3. Acesse o Airflow

```
URL:      http://localhost:8080
UsuÃ¡rio:  airflow
Senha:    airflow
```

### 4. Ative a DAG

No painel do Airflow, localize a DAG do pipeline meteorolÃ³gico e ative-a. O pipeline irÃ¡ executar automaticamente conforme o agendamento configurado, ou vocÃª pode disparÃ¡-lo manualmente clicando em **"Trigger DAG"**.

### 5. Executar manualmente (opcional)

```bash
python main.py
```

---

## ğŸ“Š Dados Coletados

Os dados meteorolÃ³gicos referem-se Ã  cidade de **Votuporanga, SÃ£o Paulo, Brasil**, e incluem variÃ¡veis como temperatura, umidade, precipitaÃ§Ã£o e demais mÃ©tricas climÃ¡ticas disponibilizadas pela fonte da API.

---

## ğŸ“ Estrutura Detalhada

```
config/
â””â”€â”€ .env                    â† Chave API, Database, User do Database, Senha Database

dags/
â””â”€â”€ weather_dag.py          â† DefiniÃ§Ã£o das tasks e dependÃªncias no Airflow

src/
â”œâ”€â”€ extract_data.py         â† Coleta dos dados via API meteorolÃ³gica
â”œâ”€â”€ transform_data.py       â† Limpeza e transformaÃ§Ã£o dos dados
â””â”€â”€ load_data.py            â† InserÃ§Ã£o no banco PostgreSQL

notebooks/
â””â”€â”€ *.ipynb                 â† ExploraÃ§Ã£o e validaÃ§Ã£o dos dados

docker-compose.yaml         â† ServiÃ§os: Airflow + PostgreSQL
main.py                     â† ExecuÃ§Ã£o manual do pipeline completo
pyproject.toml              â† ConfiguraÃ§Ã£o de dependÃªncias Python
```

---

## ğŸ” Monitoramento

Com o Airflow rodando, vocÃª pode:

- Visualizar o status de cada execuÃ§Ã£o (run) da DAG
- Inspecionar logs de cada task individualmente
- Reprocessar execuÃ§Ãµes com falha
- Acompanhar o histÃ³rico de runs no grÃ¡fico de Gantt

Acesse tudo em: `http://localhost:8080`

---

## ğŸ—„ï¸ Banco de Dados

Os dados sÃ£o armazenados no **PostgreSQL** provisionado via Docker. Para conectar com uma ferramenta como DBeaver ou TablePlus:

---

## ğŸ“¦ DependÃªncias

As dependÃªncias Python estÃ£o definidas em `pyproject.toml`. Para instalar localmente (fora do Docker):

```bash
pip install -e .
```

---

## ğŸ‘¤ Autor

**Mateus Vicentin**
[github.com/mateusvicentin](https://github.com/mateusvicentin)


